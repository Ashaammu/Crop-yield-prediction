#Transfer learning
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import numpy as np

# Load pre-trained VGG16 model without the top layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Create your regression model on top of the pre-trained base model
model = Sequential([
    base_model,
    tf.keras.layers.Flatten(),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(1)  # For regression, output layer with one neuron
])

from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Assuming you have loaded or created your dataset and assigned it to X_train and y_train

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

import numpy as np

# Convert the Series to a NumPy array
X_train_array = X_train.to_numpy()

# Reshape the array
X_train_reshaped = X_train_array.reshape(-1, 1)

# Determine the shape of your input data
input_shape = X_train_reshaped.shape[1]

# Define your model
model = Sequential()
model.add(Dense(64, input_shape=(input_shape,)))
model.add(Dense(1))


# Compile the model
model.compile(optimizer=Adam(), loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

# Compile the model
model.compile(optimizer=Adam(), loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

# Plot training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.metrics import r2_score

# Assuming you have loaded or created your dataset and assigned it to X_train and y_train

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)


import numpy as np

# Convert the Series to a NumPy array
X_train_array = X_train.to_numpy()

# Reshape the array
X_train_reshaped = X_train_array.reshape(-1, 1)

# Determine the shape of your input data
input_shape = X_train_reshaped.shape[1]

# Define your model
model = Sequential()
model.add(Dense(64, input_shape=(input_shape,)))
model.add(Dense(1))
# Compile the model
model.compile(optimizer=Adam(), loss='mean_squared_error')

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

# Get predictions on training and validation sets
y_train_pred = model.predict(X_train)
y_val_pred = model.predict(X_val)

# Calculate R2 score
r2 = r2_score(y_train, y_train_pred)
r2_val = r2_score(y_val, y_val_pred)

# Get training and validation loss from history
training_loss = history.history['loss'][-1]
validation_loss = history.history['val_loss'][-1]

print("Training Loss:", training_loss)
print("Validation Loss:", validation_loss)
print("R2 Score", r2)
x_ax = range(len(y_val_pred))
plt.scatter(x_ax, y_val, s=5, color="blue", label="original")
plt.plot(x_ax, y_val_pred, lw=0.8, color="red", label="predicted")
#plt.legend()
plt.show()


 
